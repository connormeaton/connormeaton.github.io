---
title: 'The Drive to Ineffective Altruism'
date: 2021-01-08
permalink: /posts/2021/01/the-drive-to-ineffective-altruism/
tags:
  -
---

### TL;DR:

Our morality should be updated to make room for more data-driven rationality, but we must maintain an irrational sliver of compassion to insulate us against losing our humanity.

---

Recently I finished Dostoevsky’s “The Idiot” and listened to Sam Harris’ podcast with William Macaskill on effective altruism in the same week. This was confusing. After jumping into the confluence of these two credible but polarizing moral authorities, I have less clarity on the “what do I do?” problem than when I remained on dry land, ignorant to the depths of these two tributaries of thought. Despite the apparent unsolvable nature of this problem, my time trying to stay afloat in these immiscible currents has yielded two ideas, the drive to ineffective altruism and the 1v99 paradox. I think they might be useful in understanding morality and particularly when defining objective and cost functions for decision making. 

Effective altruism (EA) is a rich and developed community of which I am just beginning to learn about. I’m probably missing something, but EA seems to be a methodology for empirically evaluating the efficacy of an altruistic act according to some previously defined objective function, such as the minimization of unnecessary suffering. I admit to having held biases against the idea due to its hyper-rational roots, which the Hayekian in me tends to associate with naivety as much as I do progress. After closer inspection, I still see naivety (which I’ll get into later), but less than I imagined and more progress potential than I expected. 
EA in action appears to be a piercingly sharp tool to carve actionable possibility out of the world of chaos. Particularity, I am pretty excited by these points:

-	With careful reliance on the quantifiable, EA provides decision-making tools other than pure feeling, which often runs counter to data.
-	EA creates a suffering-reduction marketplace, enabling charities to compete for my dollar via transparent proof of effective and cheap outcomes. This allows me to shed skepticisms of things like bureaucratic bloat and focus more on things like love. 
-	EA, though it appears to tilt left, seems to be agnostic to individual motivation, compatible with drive to fulfill divine duty, justify existence, be remembered on the right side of history, or simply feel good.

This is great because I want my potentially donated dollars to effectively minimize suffering (otherwise I could just buy a dirt bike). However, there’s a catch, or rather a few catches. The first catch is that if I practice EA, it doesn’t feel like an is actually minimizing suffering. This is where I imagine most get caught up. For example, if I actually cared about the minimization of unnecessary suffering, I would maximize my salary in a not-directly-destructive industry (software?) because I can, live below my means, and give all of my extra cash to buying malaria-preventing bug nets in a country I’ve never been to. No soup kitchens, no animal shelters, no anti-pollution marches, just writing code and sending checks. I said this was a catch, but I think it’s more of a harsh and necessary call to update our morality to the modern world full of impersonal yet real data. This alone probably deserves a deeper look sometime later.

However, as tempting as it is to perform enough mental gymnastics to convince myself of this straight and narrow path, I really don’t want to. Logically, this would imply that I do not want to minimize unnecessary suffering. Maybe this is true, and maybe I’m more selfish than I care to admit. I would also guess that you, like me, naturally place a lot of importance on feeling like you’re doing good by the world. Here in lies the drive for ineffective altruism.

Ineffective altruism, like effective altruism, is a course of action geared towards doing good in the world, but without any objective function or parameters to optimize that we can easily articulate. It’s feeling based. I think this is how most of us act, which is weird, because it seems grossly misguided in 2021. Given the right argument, I’m open to being convinced that this is drive belongs in the once-useful-now-damaging bucket that would be best to overcome, like the drive to crush 3 sleeves of Oreos in one sitting. However, drives exist for a reason. Before casting this old wineskin aside, I want to make every effort to squeeze out any drops of millennia-aged wine welled up in the tired crevasses. This is where Dostoevsky’s “The Idiot” becomes relevant.

Briefly, the Prince is the protagonist of the “The Idiot” and Dostoevsky’s (second) most sincere and nuanced attempt to detail a morally perfect man (no character can top my boy Alyosha). While I love the Prince and many of his qualities such as honesty, seriousness, and authenticity, he is a terribly ineffective altruist. In one example among many, he’s loaded yet spends his money on champagne for the Russian aristocracy. He could have spent that money on any of the myriad of cheap things 19th century Russian peasants needed to minimize suffering, like clothes and food. His dollars could have gone a long way, especially back then when the charitable orchard was still ripe with low hanging fruit. By the effective altruist standards, he squandered his wealth. This being said, why is the Prince such an ideal character that we mostly love?

The core of the Prince’s morality seems to be that he places compassion above reason and never ceases to serve others, even when the others cannot, or do not want to be served. He even does this when those he helps try to hurt him out of malevolent disdain, like Nastasya and Rogozhin do throughout the novel. This drive is best represented by the biblical parable of The Good Shepherd. See Luke 15:3-7 below:

“He told them this parable. "Which of you men, if you had one hundred sheep, and lost one of them, wouldn't leave the ninety-nine in the wilderness, and go after the one that was lost, until he found it? When he has found it, he carries it on his shoulders, rejoicing. When he comes home, he calls together his friends, his family and his neighbors, saying to them, 'Rejoice with me, for I have found my sheep which was lost!' “

This is beautiful and touching, but it also seems like terrible shepherding.  Let’s assume a shepherd’s objective is to minimize unnecessary sheep suffering and to maximize harvest to support his family. Leaving the 99 vulnerable to wolf predation to save 1 sheep who, by the sounds of it has terrible survival skills and is likely to have already been eaten, seems like the non-optimal option (imagine what his wife would say when he gets home with 1 sheep). However, whether we like it or not, this idea, which we’ll call the 1v99 Paradox, is foundational to our moral code. Its prevalence over thousands of years must yield some adaptive advantage. You don’t even need to be a bleeding-heart-Dostoevsky-reading romantic to know this. If fantasy is more your thing, I know that you loved it when Harry, the only person capable of destroying Voldemort and saving everybody, risked his life to rescue slimy Draco from his own fiery destruction. If you’re more of a no-nonsense reality buff, I’ll bet you watch old war movies where competent generals abandon the safety of their post (risking the outcome of the entire war) to save a private, and that you lap it up with a big ol’ spoon.

Herein lies the conundrum of the 1v99 Paradox. EA’s say saving the 1 is way too costly and we should focus on incremental, cheap, and reliable improvements for the 99. Fair enough. However, if there is anything worthwhile in our intrinsic objection to such logic, it may be that at some or many points in our lives, we are the 1. No one deliberately wants to live in a society that generally feels fine abandoning you because you’ve wandered into an inefficient conundrum. Potentially even more important, if we abandon the 1v99 paradox then we can tolerate the loss of 1 for the gain of 99. When we bake this ethic into sufficiently powerful central planning agencies and allow the figures to scale by the millions, we get genocide. 

I know that sounds extreme, but the 20th century saw plenty of government influenced genocide and/or mass starvation and I would care not to make a pattern of it. Such atrocity was often tolerated and even supported by really smart people thinking they were doing good by the world (like EA’s). I, along with all of my educated and progressive friends, probably would have been Bolsheviks. Our reliance on statistically-buttressed utopian dreams would have cultivated the callousness to do the dirty work of breaking eggs (read: killing millions of people) for the omelet of the future. Stalin himself summed this whole notion up perfectly when he said, “One death is a tragedy, one million is a statistic.”.

Last, there is one more fallacy that may pollute EA thinking which the 1v99 Paradox may insulate us from. This fallacy is that the world is not exactly how we see it. Our sensory perception systems filter out nearly all of the raw signal of the world. As a result, we think we know what’s going on, but we really don’t. We’re pretty clever and make pretty good guesses about the nature of things and those guesses get better every day, but I’m not betting on ultimate knowing. With EA, our judgement of effective or ineffective is based on assumed understanding of data built upon many layers of abstraction. This is amazingly efficient and often the right way to go, but every layer of abstraction is a moving part prone to error. The 1v99 Paradox relies on no abstraction. One sees suffering in front of them and one tries to stop it. The distributed nature of this system may be less efficient, but it provides immediate, abstraction-free feedback making it less prone to the error at scale we saw in the last century.

Statistical thinking is an incredible tool and we should use it as best as we can as much as possible. It may be the most optimal way to meet our objective functions, but at what cost? In the past, planner-based utopia-building activity caused some of our brightest to lose their sense of tragedy, of humanity. I can’t help but think about this as we outsource more and more of our decision making to machines that consume incomprehensible swaths of data using black-box algorithms. In this world, the preservation of the irrational 1v99 Paradox may insulate us from statistical destruction. Our awareness is crucial because unless we’re in the relatively small 1-group (which, remember, could be millions), we will not even notice what is happening. Totalitarianism is totally fine, maybe even better, if we’re in the right.




	 
